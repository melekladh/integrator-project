# E-commerce FAQ Chatbot - API FastAPI

Une API FastAPI pour un chatbot FAQ e-commerce utilisant ChromaDB pour la recherche sÃ©mantique et llama-cpp-python pour la gÃ©nÃ©ration de rÃ©ponses basÃ©e sur un modÃ¨le local.

## ğŸ“‹ Architecture du Projet

```
integrator project/
â”œâ”€â”€ main.py                                  # Application FastAPI principale
â”œâ”€â”€ app.py                                   # Script d'initialisation des donnÃ©es
â”œâ”€â”€ requirements.txt                         # DÃ©pendances Python
â”œâ”€â”€ Dockerfile                               # Configuration Docker
â”œâ”€â”€ docker-compose.yml                       # Orchestration des services
â”œâ”€â”€ Ecommerce_FAQ_Chatbot_dataset.json      # Dataset FAQ
â”œâ”€â”€ dolphin-2.6-mistral-7b.Q2_K.gguf        # ModÃ¨le GGUF local
â””â”€â”€ utils/
    â”œâ”€â”€ load_data.py                        # Charge les FAQs depuis JSON
    â”œâ”€â”€ init_chroma.py                      # Initialise ChromaDB
    â”œâ”€â”€ add_to_chroma.py                    # Ajoute documents Ã  ChromaDB
    â”œâ”€â”€ search.py                           # Recherche sÃ©mantique
    â””â”€â”€ generate.py                         # GÃ©nÃ©ration de rÃ©ponses
```

### ğŸ—ï¸ Composants Principaux

- **FastAPI** : Framework web pour crÃ©er l'API REST
- **ChromaDB** : Base de donnÃ©es vectorielle pour la recherche sÃ©mantique
- **llama-cpp-python** : ExÃ©cution du modÃ¨le LLM local (Dolphin Mistral)
- **Pydantic** : Validation des donnÃ©es

## ğŸš€ Installation

### Option 1 : Installation Locale (RecommandÃ©e)

**PrÃ©requis :**
- Python 3.13+
- pip

**Ã‰tapes :**

```bash
# 1. Clonez ou ouvrez le rÃ©pertoire du projet
cd /Users/macbookair/Desktop/integrator\ project

# 2. CrÃ©ez un environnement virtuel (si nÃ©cessaire)
python3 -m venv .venv

# 3. Activez l'environnement virtuel
source .venv/bin/activate

# 4. Installez les dÃ©pendances
pip install -r requirements.txt

# 5. (Optionnel) Si vous avez llama-cpp-python
# pip install llama-cpp-python
```

### Option 2 : Installation avec Docker

**PrÃ©requis :**
- Docker Desktop installÃ© et en cours d'exÃ©cution

**Ã‰tapes :**

```bash
# 1. Naviguez vers le rÃ©pertoire du projet
cd /Users/macbookair/Desktop/integrator\ project

# 2. Construisez les images (premiÃ¨re fois, ~15-20 minutes)
docker-compose build

# 3. Lancez les services
docker-compose up -d

# 4. VÃ©rifiez que tout fonctionne
docker-compose ps
```

## ğŸƒ ExÃ©cution du Projet

### Option 1 : ExÃ©cution Locale

**DÃ©marrer l'API :**

```bash
# Activez l'environnement virtuel
source .venv/bin/activate

# Lancez l'API FastAPI
uvicorn main:app --port 8000 --reload
```

L'API sera disponible sur : **http://127.0.0.1:8000**

**Documentation interactive (Swagger UI) :**
- http://127.0.0.1:8000/docs

### Option 2 : ExÃ©cution avec Docker

```bash
# Lancer les services en arriÃ¨re-plan
docker-compose up -d

# VÃ©rifier les logs
docker-compose logs -f fastapi

# ArrÃªter les services
docker-compose down
```

L'API sera disponible sur : **http://localhost:8000**

## ğŸ“¡ Endpoints API

### 1. Health Check
```
GET /
```
Retourne la version et l'URL Swagger.

**RÃ©ponse :**
```json
{
  "version": "1.0.0",
  "swagger": "/docs"
}
```

### 2. Rechercher des Documents
```
POST /search
```
Recherche les documents FAQ pertinents pour une requÃªte.

**RequÃªte :**
```json
{
  "query": " What payment methods do you accept?"
}
```

**RÃ©ponse :**
```json
{
  "query": "What payment methods do you accept?",
  "top_documents": [...]
}
```

### 3. GÃ©nÃ©rer une RÃ©ponse
```
POST /generate
```
GÃ©nÃ¨re une rÃ©ponse basÃ©e sur la recherche sÃ©mantique et le modÃ¨le LLM.

**RequÃªte :**
```json
{
  "query": "What payment methods do you accept?"
}
```

**RÃ©ponse :**
```json
{
  "query": "What payment methods do you accept?",
  "answer": "Pour crÃ©er un compte, veuillez...",
  "source_documents": [...]
}
```

## ğŸ”§ Configuration

### Variables d'Environnement (Docker)

Dans `docker-compose.yml` :
```yaml
environment:
  - CHROMA_PERSISTENCE_DIR=/app/chroma_data
```

### ParamÃ¨tres de Recherche

Modifiez le nombre de documents retournÃ©s dans [main.py](main.py#L32):
```python
documents = search_documents(collection, request.query, k=5)  # k = nombre de rÃ©sultats
```

## ğŸ“¦ DÃ©pendances

Voir [requirements.txt](requirements.txt) pour la liste complÃ¨te.

**Principales :**
- fastapi==0.104.1
- uvicorn==0.24.0
- chromadb==0.4.17
- pydantic==2.5.0
- llama-cpp-python==0.2.36 (optionnel, pour la gÃ©nÃ©ration)




## ğŸ“ Initialisation des DonnÃ©es

Pour charger les donnÃ©es FAQ dans ChromaDB :

```bash
# Activez l'environnement virtuel
source .venv/bin/activate

# ExÃ©cutez le script d'initialisation
python3 app.py
```

Cela va :
1. Charger les FAQs depuis `Ecommerce_FAQ_Chatbot_dataset.json`
2. CrÃ©er une collection ChromaDB
3. Ajouter les documents Ã  la base vectorielle

## ğŸ¯ Cas d'Usage

1. **Chatbot FAQ** : RÃ©pondre automatiquement aux questions clients
2. **Recherche** : Trouver les articles pertinents de la FAQ
3. **Support Client** : IntÃ©grer l'API dans un systÃ¨me de support

## ğŸ“„ Licence

Ã€ complÃ©ter selon vos besoins.

## ğŸ‘¥ Auteur

CrÃ©Ã© le : FÃ©vrier 2026

---

**Questions ?** Consultez la documentation FastAPI : https://fastapi.tiangolo.com/
